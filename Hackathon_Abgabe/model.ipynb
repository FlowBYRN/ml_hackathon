{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import LinearRegression\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def preprocess(dataset,initial_instance_count):\n",
    "    if 'Verkaufspreis' in dataset.columns:\n",
    "        # Deleting missing values, since there are only less than 1% of missing values\n",
    "        dataset = dataset.dropna(subset=['Wohngebiet', 'Funktionalitaet', 'KuechenQualitaet', 'Elektrik',\n",
    "                            'Verkaufstyp', 'Garagenflaeche', 'Garagenautos'])\n",
    "        \n",
    "        # Fill missing values with Linear Regression prediction in feature 'Strassenlaenge'\n",
    "        model = LinearRegression()\n",
    "        model.fit(np.array(dataset[dataset['Strassenlaenge'].notna()].Verkaufspreis).reshape(-1, 1), \n",
    "                dataset[dataset['Strassenlaenge'].notna()].Strassenlaenge)\n",
    "        predicted_values = model.predict(np.array(dataset[dataset['Strassenlaenge'].isna()].Verkaufspreis).reshape(-1, 1))\n",
    "        dataset.loc[dataset['Strassenlaenge'].isnull(), 'Strassenlaenge'] = predicted_values\n",
    "    else:\n",
    "        dataset['Strassenlaenge'] = dataset['Strassenlaenge'].fillna(dataset['Strassenlaenge'].mode()[0])\n",
    "\n",
    "        features_fillna_mode = ['Wohngebiet', 'Funktionalitaet', 'KuechenQualitaet', 'Elektrik',\n",
    "                            'Verkaufstyp', 'Garagenflaeche', 'Garagenautos']\n",
    "        for feature in features_fillna_mode:\n",
    "            dataset[feature] = dataset[feature].fillna(dataset[feature].mode()[0])\n",
    "\n",
    "\n",
    "    # Fill missing values with mode\n",
    "    features_fillna_mode = ['Funktionalitaet', 'KuechenQualitaet', 'Elektrik', 'Garagenbaujahr',\n",
    "                            'Garageninnenausbau', 'Garagentyp']\n",
    "    for feature in features_fillna_mode:\n",
    "        dataset[feature] = dataset[feature].fillna(dataset[feature].mode()[0])\n",
    "\n",
    "\n",
    "    # Fill missing values with NA\n",
    "    features_fillna_nan = ['Kellerhoehe', 'Kellerzustand', 'Kellerbelichtung', \n",
    "                        'Kellerbereich1', 'Kellerbereich2', 'Kaminqualitaet',\n",
    "                        'Zaunqualitaet']\n",
    "    for feature in features_fillna_nan:\n",
    "        dataset[feature] = dataset[feature].fillna('NA')\n",
    "\n",
    "\n",
    "    # Fill missing values with 0.0\n",
    "    features_fillna_0 = ['Kellerbereichgroesse1', 'Kellerbereichgroesse2', 'KellerbereichgroesseGes', \n",
    "                        'KellerbereichgroesseNAu', 'KellerVollbadezimmer', 'KellerHalbbadezimmer',\n",
    "                        'Mauerwerkflaeche']\n",
    "    for feature in features_fillna_0:\n",
    "        dataset[feature] = dataset[feature].fillna(0.0)\n",
    "\n",
    "    # Fill Mauerwerktyp with 'Kein'\n",
    "    dataset['Mauerwerktyp'] = dataset['Mauerwerktyp'].fillna('Kein')\n",
    "\n",
    "\n",
    "    # Deleting features 'Versorgung' because there are 2 missing values and others are 'EGWA'\n",
    "    # Deleting features 'Kellerbereichgroesse2' because there are no good distribution of values \n",
    "    # Delete other features because they have too many null values\n",
    "    dataset = dataset.drop(['Versorgung', 'Kellerbereichgroesse2', 'GeringequalitaetFlaeche',\n",
    "                'Zufahrtsweg', 'Sondermerkmal', 'Poolqualitaet',\n",
    "                'Garagenqualitaet', 'Garagenzustand'], axis=1)\n",
    "    \n",
    "    if 'Verkaufspreis' in dataset.columns:\n",
    "        # Limit 'Grundstuecksgroesse' with 6000 m2\n",
    "        dataset = dataset[dataset['Grundstuecksgroesse'] < 6000]\n",
    "\n",
    "        # Limit 'Strassenlaenge' with 60 m\n",
    "        dataset = dataset[dataset['Strassenlaenge'] <= 60]\n",
    "\n",
    "        # Delete instance 714 because there Baujahr is bigger than Umbaujahr\n",
    "        dataset = dataset[dataset['Umbaujahr'] >= dataset['Baujahr']]\n",
    "\n",
    "        # Delete Garagenbaujahr bigger than 2023\n",
    "        dataset = dataset[dataset['Garagenbaujahr'] < 2023]\n",
    "\n",
    "    # Delete 'Bedingung2' because there are only 13 values which are not 'Norm'\n",
    "    dataset = dataset.drop('Bedingung2', axis=1)\n",
    "\n",
    "    # Merge values EbOA, EbOU, EbNA, EbNU into 'Hbf' and PosN, PosA into 'Pos' for 'Bedingung1' feature\n",
    "    dataset['Bedingung1'] = dataset['Bedingung1'].replace(['EbOA', 'EbOU', 'EbNA', 'EbNU'], 'Hbf')\n",
    "    dataset['Bedingung1'] = dataset['Bedingung1'].replace(['PosN', 'PosA'], 'Pos')\n",
    "\n",
    "    # Delete features 'Grundstuecksform', 'Gelaendeneigun', 'Strassentyp', 'Dachmaterial' because of bad distribution of values\n",
    "    dataset = dataset.drop(['Grundstuecksform', 'Gelaendeneigung', 'Strassentyp', 'Dachmeterial'], axis=1)\n",
    "    \n",
    "    final_instance_count = len(dataset)\n",
    "    final_feature_count = len(dataset.columns)\n",
    "\n",
    "    print(f'{initial_instance_count - final_instance_count} '\n",
    "        f'({round((initial_instance_count - final_instance_count) / initial_instance_count * 100, 3)}%)'\n",
    "        f' Exemplare wurden entfernt. \\nAnzahle von Exemplare: {final_instance_count}'\n",
    "        f'\\nAnzahle von Merkmale: {final_feature_count}')\n",
    "    \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning (Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahle von Exemplare: 2000\n",
      "Anzahle von Merkmale: 80\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "df = pd.read_csv('train.csv', index_col='Id')\n",
    "\n",
    "initial_instance_count = len(df)\n",
    "initital_feature_count = len(df.columns)\n",
    "\n",
    "print(f'Anzahle von Exemplare: {initial_instance_count}\\nAnzahle von Merkmale: {initital_feature_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 (0.7%) Exemplare wurden entfernt. \n",
      "Anzahle von Exemplare: 1986\n",
      "Anzahle von Merkmale: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weidn\\AppData\\Local\\Temp\\ipykernel_3944\\406425908.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[feature] = dataset[feature].fillna(dataset[feature].mode()[0])\n",
      "C:\\Users\\weidn\\AppData\\Local\\Temp\\ipykernel_3944\\406425908.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[feature] = dataset[feature].fillna('NA')\n",
      "C:\\Users\\weidn\\AppData\\Local\\Temp\\ipykernel_3944\\406425908.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[feature] = dataset[feature].fillna(0.0)\n",
      "C:\\Users\\weidn\\AppData\\Local\\Temp\\ipykernel_3944\\406425908.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['Mauerwerktyp'] = dataset['Mauerwerktyp'].fillna('Kein')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = preprocess(df,initial_instance_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wohngebiet                    0\n",
       "GeschlosseneVerandaflaeche    0\n",
       "Funktionalitaet               0\n",
       "OberirdischeVollbadezimmer    0\n",
       "OberirdischeHalbbadezimmer    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning (Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahle von Exemplare: 919\n",
      "Anzahle von Merkmale: 79\n"
     ]
    }
   ],
   "source": [
    "df_test_id = pd.read_csv('test.csv')\n",
    "df_test = df_test_id.drop('Id', axis=1)\n",
    "initial_instance_count_test = len(df_test)\n",
    "initital_feature_count_test = len(df_test.columns)\n",
    "\n",
    "print(f'Anzahle von Exemplare: {initial_instance_count_test}\\nAnzahle von Merkmale: {initital_feature_count_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (0.0%) Exemplare wurden entfernt. \n",
      "Anzahle von Exemplare: 919\n",
      "Anzahle von Merkmale: 66\n"
     ]
    }
   ],
   "source": [
    "df_test = preprocess(df_test,initial_instance_count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:  (1986, 67) (919, 66)\n",
      "after:  (1986, 244) (919, 244)\n"
     ]
    }
   ],
   "source": [
    "print('before: ',df.shape, df_test.shape)\n",
    "combined = pd.concat([df, df_test], axis=0, sort=False)\n",
    "\n",
    "combined_encoded = pd.get_dummies(combined)\n",
    "\n",
    "#split again\n",
    "train_encoded, test_encoded = combined_encoded.iloc[:len(df), :], combined_encoded.iloc[len(df):, :]\n",
    "print('after: ',train_encoded.shape, test_encoded.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoded = test_encoded.drop('Verkaufspreis', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1986, 243) (1986,)\n"
     ]
    }
   ],
   "source": [
    "y = train_encoded['Verkaufspreis']\n",
    "X_encoded = train_encoded.drop('Verkaufspreis', axis=1)\n",
    "print(X_encoded.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# df_encoded = pd.get_dummies(df)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.9185381126979804\n",
      "Mean Squared Error: 292273277.59365636\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# We searched the best hyperparameters with RandomizedSearchCV\n",
    "forest = RandomForestRegressor(random_state=42, n_estimators=800,min_samples_split=2,min_samples_leaf=1,max_features='sqrt',max_depth=40,bootstrap=False )\n",
    "\n",
    "# Train the model\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred = forest.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R^2 Score:\", r2)\n",
    "\n",
    "# Calculate mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = forest.predict(test_encoded)\n",
    "\n",
    "prediction_avg = pd.read_csv(\"prediction_avg.csv\")\n",
    "\n",
    "prediction_avg[\"Verkaufspreis\"] = predicted\n",
    "\n",
    "prediction_avg.to_csv('prediction_avg.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
